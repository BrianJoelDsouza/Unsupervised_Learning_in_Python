{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "***\n",
    "***\n",
    "<br><h1>A3: Timed Unsupervised Learning Project</h1>\n",
    "<h2> Machine Learning </h2><br><br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Importing the necessary python packages that are needed for the analysis</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                as pd                      # data science essentials\n",
    "import matplotlib.pyplot     as plt                     # fundamental data visualization\n",
    "import seaborn               as sns                     # enhanced visualization\n",
    "from sklearn.preprocessing   import StandardScaler      # standard scaler\n",
    "from sklearn.decomposition   import PCA                 # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Running the User defined functions that will be used throughout our analysis</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "########################################\n",
    "# inertia plot\n",
    "########################################\n",
    "def inertia_plot(data, max_clust = 50):\n",
    "    \"\"\"\n",
    "PARAMETERS\n",
    "----------\n",
    "data      : DataFrame, data from which to build clusters. Dataset should be scaled\n",
    "max_clust : int, maximum of range for how many clusters to check interia, default 50\n",
    "    \"\"\"\n",
    "\n",
    "    ks = range(1, max_clust)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        # INSTANTIATING a kmeans object\n",
    "        model = KMeans(n_clusters = k)\n",
    "\n",
    "\n",
    "        # FITTING to the data\n",
    "        model.fit(data)\n",
    "\n",
    "\n",
    "        # append each inertia to the list of inertias\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting ks vs inertias\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    plt.plot(ks, inertias, '-o')\n",
    "\n",
    "\n",
    "    # labeling and displaying the plot\n",
    "    plt.xlabel('number of clusters, k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.xticks(ks)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "***\n",
    "***\n",
    "***\n",
    "<h3>Explanatory Data Analysis</h3>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Loading the original dataset</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_excel('Survey_Data_Final_Exam.xlsx')\n",
    "\n",
    "#Viewing the dataset \n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Finding the info of the dataframe\n",
    "original_df.info() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if any columns have missing values and summing them up to find the total of missing values\n",
    "original_df.isnull().any().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the value that is missing \n",
    "original_df['What is your ethnicity?'][original_df['What is your ethnicity?'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at all the other columns of the missing row\n",
    "print(original_df.iloc[147, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Question: </strong>How is this guy 45 years old? Fake observation or someone just playing around?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the missing value \n",
    "original_df.fillna('Unanswered', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rechecking if any missing value exists\n",
    "original_df.isnull().any().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the descriptive statistics of the dataset\n",
    "original_df.loc[:, :].describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns for easier identificaition and usage\n",
    "original_df.columns = ['surveyID', \n",
    "                       'life_of_the_party', \n",
    "                       'unconcerned_for_others', \n",
    "                       'always_prepared', \n",
    "                       'stressed_out_easily', \n",
    "                       'have_rich_vocabulary', \n",
    "                       'less_talkative', \n",
    "                       'interested_in_people', \n",
    "                       'leave_belongings_around', \n",
    "                       'relaxed', \n",
    "                       'difficulty_understanding_abstract_ideas', \n",
    "                       'comfortable_around_people', \n",
    "                       'insult_people', \n",
    "                       'attention_to_detail',\n",
    "                       'worrisome', \n",
    "                       'vivid_imagination', \n",
    "                       'keep_in_the_background', \n",
    "                       'sympathetic', \n",
    "                       'messy_person', \n",
    "                       'seldom_feel_blue', \n",
    "                       'uninterested_in_abstract_ideas', \n",
    "                       'starts_conversations', \n",
    "                       'uninterested_in_peoples_problems', \n",
    "                       'get_chores_done', \n",
    "                       'easily_disturbed', \n",
    "                       'have_excellent_ideas', \n",
    "                       'have_little_to_say', \n",
    "                       'soft_hearted', \n",
    "                       'forget_to_put_things_back', \n",
    "                       'get_upset_easily', \n",
    "                       'no_good_imagination', \n",
    "                       'socialize_at_parties', \n",
    "                       'uninterested_in_others', \n",
    "                       'like_order', \n",
    "                       'moody', \n",
    "                       'quick_at_understanding_things', \n",
    "                       'averts_attention_to_self', \n",
    "                       'take_time_out_for_others', \n",
    "                       'avoids_duties', \n",
    "                       'mood_swings',\n",
    "                       'use_difficult_words', \n",
    "                       'likes_being_center_of_attention', \n",
    "                       'feel_others_emotions', \n",
    "                       'follows_schedule', \n",
    "                       'irritated_easily', \n",
    "                       'reflects_on_things', \n",
    "                       'quite_around_strangers', \n",
    "                       'make_people_feel_at_ease', \n",
    "                       'exacting_at_work', \n",
    "                       'feels_blue', \n",
    "                       'full_of_ideas', \n",
    "                       'sees_underlying_patters_in_complex_situations', \n",
    "                       'dont_generate_new_ideas',\n",
    "                       'aware_of_personal_strengths/weakness', \n",
    "                       'growth_mindset', \n",
    "                       'responds_effectively_to_priorities', \n",
    "                       'takes_initiative', \n",
    "                       'encourages_direct/open_discussions', \n",
    "                       'responds_effectively_to_priorities(duplicate)', \n",
    "                       'takes_initiative(duplicate)', \n",
    "                       'encourages_direct/open_discussions(duplicate)', \n",
    "                       'good_listener', \n",
    "                       'dont_persuasively_sell_vision/idea', \n",
    "                       'builds_cooperative_relationships', \n",
    "                       'works_well_with_people_from_diverse_cultures', \n",
    "                       'effectively_negotiates_interests/resources/roles', \n",
    "                       'cant_rally_team_towards_common_goal', \n",
    "                       'translates_ideas_into_plans_that_are_organized/realistic', \n",
    "                       'resolves_conflicts_constructively', \n",
    "                       'seeks/uses_teammates_feedback', \n",
    "                       'coaches_teammates_for_performance/growth', \n",
    "                       'drive_for_results', \n",
    "                       'current_laptop', \n",
    "                       'preferred_laptop', \n",
    "                       'program', \n",
    "                       'age', \n",
    "                       'gender',\n",
    "                       'nationality', \n",
    "                       'ethnicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Finding the value counts of categorical variables\n",
    "print(original_df.loc[:, 'current_laptop'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(original_df.loc[:, 'preferred_laptop'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(original_df.loc[:, 'program'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(original_df.loc[:, 'gender'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(original_df.loc[:, 'nationality'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(original_df.loc[:, 'ethnicity'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of current laptop brand per answer\n",
    "\n",
    "current_laptop = original_df.loc[:, 'current_laptop']\n",
    "\n",
    "current_windows    = 0\n",
    "current_macbook    = 0\n",
    "current_chromebook = 0\n",
    "current_total      = 0\n",
    "\n",
    "for brand in current_laptop:\n",
    "    if brand == \"Windows laptop\":\n",
    "        current_windows += 1\n",
    "        current_total += 1\n",
    "    \n",
    "    elif brand == 'Chromebook':\n",
    "        current_chromebook += 1\n",
    "        current_total += 1\n",
    "        \n",
    "    else:\n",
    "        current_macbook += 1\n",
    "        current_total += 1\n",
    "\n",
    "perc_windows = round((current_windows/current_total) * 100, 1)\n",
    "perc_macbook = round((current_macbook/current_total) * 100, 1)\n",
    "perc_chromebook = round((current_chromebook/current_total) * 100, 1)\n",
    "\n",
    "print(f\"\"\"\n",
    "        Total computers:           {current_total}\n",
    "        Total current Windows:     {current_windows}, a {perc_windows}% of the total.\n",
    "        Total current Macbooks:    {current_macbook}, a {perc_macbook}% of the total.\n",
    "        Total current Chromebooks: {current_chromebook}, a {perc_chromebook}% of the total.\n",
    "        _____________________________________________________\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of preferred laptop brand per answer\n",
    "\n",
    "preferred_laptop_laptop = original_df.loc[:, 'preferred_laptop']\n",
    "\n",
    "preferred_laptop_windows    = 0\n",
    "preferred_laptop_macbook    = 0\n",
    "preferred_laptop_chromebook = 0\n",
    "preferred_laptop_total      = 0\n",
    "\n",
    "for brand in preferred_laptop_laptop:\n",
    "    if brand == \"Windows laptop\":\n",
    "        preferred_laptop_windows += 1\n",
    "        preferred_laptop_total += 1\n",
    "    \n",
    "    elif brand == 'Chromebook':\n",
    "        preferred_laptop_chromebook += 1\n",
    "        preferred_laptop_total += 1\n",
    "        \n",
    "    else:\n",
    "        preferred_laptop_macbook += 1\n",
    "        preferred_laptop_total += 1\n",
    "\n",
    "diff_wind = preferred_laptop_windows - current_windows\n",
    "diff_mac = preferred_laptop_macbook - current_macbook\n",
    "\n",
    "change_windows = round(((preferred_laptop_windows - current_windows)/current_windows) * 100, 1)\n",
    "change_macbook = round(((preferred_laptop_macbook - current_macbook)/current_macbook) * 100, 1)\n",
    "#change_chromebook = round((preferred_laptop_chromebook/target_total) * 100, 1)\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "        Total computers:             {preferred_laptop_total}\n",
    "        Total preferred Windows:     {preferred_laptop_windows}, a change of {diff_wind} units ({change_windows}%).\n",
    "        Total preferred Macbooks:    {preferred_laptop_macbook}, a change of {diff_mac} units ({change_macbook}%).\n",
    "        Total preferred Chromebooks:  {preferred_laptop_chromebook}, a new player!\n",
    "        _____________________________________________________\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT 1:</strong><br>\n",
    "When it comes to branding and operating system, the sample is evenly distributed. In this sense, 51% of the survey owns a Macbook (200 people), and 49% have a Windows laptop. However, in the context of all devices having the same retail price, the distribution would change as follows: Macbook would increase by 19 units (56% of total), Windows would decrease by 29 units (41.5% of total), and Chromebook would have 10 units (2.5%). Note that although Macbook increased in total units, it would lose 16 users to Windows, and 3 users to Chromebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>To maintain the similarity between features as required in Unsupervised learning, dropping variables that do not match with the survey questions, where people gave a rating between 1 and 5</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_answers = original_df.drop(['surveyID', 'current_laptop', 'preferred_laptop', 'program', 'age', 'gender',\n",
    "                                   'nationality', 'ethnicity'], axis = 1)\n",
    "\n",
    "#Viewing the new dataset\n",
    "survey_answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Separating columns that relate to Big 5 personality traits and Hult DNA.</strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting the Big5 personality traits\n",
    "survey_answers_big5 =   survey_answers.loc[:, ['life_of_the_party', \n",
    "                                               'unconcerned_for_others', \n",
    "                                               'always_prepared', \n",
    "                                               'stressed_out_easily', \n",
    "                                               'have_rich_vocabulary', \n",
    "                                               'less_talkative', \n",
    "                                               'interested_in_people', \n",
    "                                               'leave_belongings_around', \n",
    "                                               'relaxed', \n",
    "                                               'difficulty_understanding_abstract_ideas', \n",
    "                                               'comfortable_around_people', \n",
    "                                               'insult_people', \n",
    "                                               'attention_to_detail',\n",
    "                                               'worrisome', \n",
    "                                               'vivid_imagination', \n",
    "                                               'keep_in_the_background', \n",
    "                                               'sympathetic', \n",
    "                                               'messy_person', \n",
    "                                               'seldom_feel_blue', \n",
    "                                               'uninterested_in_abstract_ideas', \n",
    "                                               'starts_conversations', \n",
    "                                               'uninterested_in_peoples_problems', \n",
    "                                               'get_chores_done', \n",
    "                                               'easily_disturbed', \n",
    "                                               'have_excellent_ideas', \n",
    "                                               'have_little_to_say', \n",
    "                                               'soft_hearted', \n",
    "                                               'forget_to_put_things_back', \n",
    "                                               'get_upset_easily', \n",
    "                                               'no_good_imagination', \n",
    "                                               'socialize_at_parties', \n",
    "                                               'uninterested_in_others', \n",
    "                                               'like_order', \n",
    "                                               'moody', \n",
    "                                               'quick_at_understanding_things', \n",
    "                                               'averts_attention_to_self', \n",
    "                                               'take_time_out_for_others', \n",
    "                                               'avoids_duties', \n",
    "                                               'mood_swings',\n",
    "                                               'use_difficult_words', \n",
    "                                               'likes_being_center_of_attention', \n",
    "                                               'feel_others_emotions', \n",
    "                                               'follows_schedule', \n",
    "                                               'irritated_easily', \n",
    "                                               'reflects_on_things', \n",
    "                                               'quite_around_strangers', \n",
    "                                               'make_people_feel_at_ease', \n",
    "                                               'exacting_at_work', \n",
    "                                               'feels_blue', \n",
    "                                               'full_of_ideas']]\n",
    "\n",
    "#Checking the results\n",
    "survey_answers_big5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing columns with Hult DNA\n",
    "survey_answers_hultdna = survey_answers.loc[:,['sees_underlying_patters_in_complex_situations', \n",
    "                                               'dont_generate_new_ideas',\n",
    "                                               'aware_of_personal_strengths/weakness', \n",
    "                                               'growth_mindset', \n",
    "                                               'responds_effectively_to_priorities', \n",
    "                                               'takes_initiative', \n",
    "                                               'encourages_direct/open_discussions', \n",
    "                                               'responds_effectively_to_priorities(duplicate)', \n",
    "                                               'takes_initiative(duplicate)', \n",
    "                                               'encourages_direct/open_discussions(duplicate)', \n",
    "                                               'good_listener', \n",
    "                                               'dont_persuasively_sell_vision/idea', \n",
    "                                               'builds_cooperative_relationships', \n",
    "                                               'works_well_with_people_from_diverse_cultures', \n",
    "                                               'effectively_negotiates_interests/resources/roles', \n",
    "                                               'cant_rally_team_towards_common_goal', \n",
    "                                               'translates_ideas_into_plans_that_are_organized/realistic', \n",
    "                                               'resolves_conflicts_constructively', \n",
    "                                               'seeks/uses_teammates_feedback', \n",
    "                                               'coaches_teammates_for_performance/growth', \n",
    "                                               'drive_for_results']]\n",
    "\n",
    "#Checking the dataset\n",
    "survey_answers_hultdna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(survey_answers_hultdna['responds_effectively_to_priorities'].corr(survey_answers_hultdna['responds_effectively_to_priorities(duplicate)']))\n",
    "#print(\"\\n\")\n",
    "#print(survey_answers_hultdna['takes_initiative'].corr(survey_answers_hultdna['takes_initiative(duplicate)']))\n",
    "#print(\"\\n\")\n",
    "#print(survey_answers_hultdna['encourages_direct/open_discussions'].corr(survey_answers_hultdna['encourages_direct/open_discussions(duplicate)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> There are 3 repeated questions, labeled as (duplicates). We will use them as is, since they look highly correlated and the PCA algorithm works fine with highly correlated explanatory variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Scaling the explanatory variables, so that they can be used in PCA and KNN clustering methods</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling the whole survey_answers explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a StandartScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the explanatory data\n",
    "scaler.fit(survey_answers)\n",
    "\n",
    "#Transforming the fit data\n",
    "survey_answers_scaled = scaler.transform(survey_answers)\n",
    "\n",
    "#Converting into a dataframe object\n",
    "survey_answers_scaled_df = pd.DataFrame(survey_answers_scaled)\n",
    "\n",
    "#Renaming the columns \n",
    "survey_answers_scaled_df.columns = survey_answers.columns\n",
    "\n",
    "#Checking the variance before and after scaling\n",
    "print(pd.np.var(survey_answers))\n",
    "print(\"\\n\")\n",
    "print(pd.np.var(survey_answers_scaled_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling the Big5 personality traits explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a StandartScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the explanatory data\n",
    "scaler.fit(survey_answers_big5)\n",
    "\n",
    "#Transforming the fit data\n",
    "survey_answers_big5_scaled = scaler.transform(survey_answers_big5)\n",
    "\n",
    "#Converting into a dataframe object\n",
    "survey_answers_big5_scaled_df = pd.DataFrame(survey_answers_big5_scaled)\n",
    "\n",
    "#Renaming the columns \n",
    "survey_answers_big5_scaled_df.columns = survey_answers_big5.columns\n",
    "\n",
    "#Checking the variance before and after scaling\n",
    "print(pd.np.var(survey_answers_big5))\n",
    "print(\"\\n\")\n",
    "print(pd.np.var(survey_answers_big5_scaled_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling the Hult DNA explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a StandartScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the explanatory data\n",
    "scaler.fit(survey_answers_hultdna)\n",
    "\n",
    "#Transforming the fit data\n",
    "survey_answers_hultdna_scaled = scaler.transform(survey_answers_hultdna)\n",
    "\n",
    "#Converting into a dataframe object\n",
    "survey_answers_hultdna_scaled_df = pd.DataFrame(survey_answers_hultdna_scaled)\n",
    "\n",
    "#Renaming the columns \n",
    "survey_answers_hultdna_scaled_df.columns = survey_answers_hultdna.columns\n",
    "\n",
    "#Checking the variance before and after scaling\n",
    "print(pd.np.var(survey_answers_hultdna))\n",
    "print(\"\\n\")\n",
    "print(pd.np.var(survey_answers_hultdna_scaled_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Creating a correlation heatmap</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plot size\n",
    "#fig, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "\n",
    "#Developing a correlation matrix object\n",
    "#survey_answers_scaled_df_corr = survey_answers_scaled_df.corr().round(2).iloc[0:19, 0:19]\n",
    "\n",
    "\n",
    "#Creating a correlation heatmap\n",
    "#sns.heatmap(survey_answers_scaled_df_corr,\n",
    "#            cmap   = 'coolwarm',\n",
    "#            square = True,\n",
    "#            annot  = True)\n",
    "\n",
    "#Display the heatmap\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plot size\n",
    "#fig, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "\n",
    "#Developing a correlation matrix object\n",
    "#survey_answers_scaled_df_corr = survey_answers_scaled_df.corr().round(2).iloc[20:39, 20:39]\n",
    "\n",
    "\n",
    "#Creating a correlation heatmap\n",
    "#sns.heatmap(survey_answers_scaled_df_corr,\n",
    "#            cmap   = 'coolwarm',\n",
    "#            square = True,\n",
    "#            annot  = True)\n",
    "\n",
    "#Display the heatmap\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plot size\n",
    "#fig, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "\n",
    "#Developing a correlation matrix object\n",
    "#survey_answers_scaled_df_corr = survey_answers_scaled_df.corr().round(2).iloc[40:59, 40:59]\n",
    "\n",
    "\n",
    "#Creating a correlation heatmap\n",
    "#sns.heatmap(survey_answers_scaled_df_corr,\n",
    "#            cmap   = 'coolwarm',\n",
    "#            square = True,\n",
    "#            annot  = True)\n",
    "\n",
    "#Display the heatmap\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plot size\n",
    "#fig, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "\n",
    "#Developing a correlation matrix object\n",
    "#survey_answers_scaled_df_corr = survey_answers_scaled_df.corr().round(2).iloc[60:71, 60:71]\n",
    "\n",
    "\n",
    "#Creating a correlation heatmap\n",
    "#sns.heatmap(survey_answers_scaled_df_corr,\n",
    "#            cmap   = 'coolwarm',\n",
    "#            square = True,\n",
    "#            annot  = True)\n",
    "\n",
    "#Display the heatmap\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>As can be seen from the correlation heatmaps, there are only a few correlations that are above 0.5 or below -0.5. Implying that we could explain high degree of variance using only a few Principal Components in PCA.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "***\n",
    "***\n",
    "***\n",
    "<h3>Principal Component Analysis</h3>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>PCA performed on the whole survey_answers_scaled explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a PCA object without specific mention of components\n",
    "#pca = PCA(n_components = None,\n",
    "#          random_state = 222)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "#pca_survey = pca.fit_transform(survey_answers_scaled)\n",
    "\n",
    "#Comparing shapes\n",
    "#print(\"Original shape:\", survey_answers_scaled.shape)\n",
    "#print(\"PCA shape     :\", pca_survey.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Plotting a Scree plot to visually detect the number of principal components to be used.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the scree plot function\n",
    "#scree_plot(pca_object=pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the Scree plot, it is a good choice to go with 7 Principal Components, as seen by the elbow of the plot at 7 PCA feature, after which there is very less change in explained variance.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanting a PCA object with just the first 7 PC's\n",
    "#pca7 = PCA(n_components = 7,\n",
    "#           random_state = 222)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "#pca7_survey = pca7.fit_transform(survey_answers_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Checking each components explained Variance ratio</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Component number counter\n",
    "#component_number = 0\n",
    "\n",
    "\n",
    "#Looping over each principal component\n",
    "#for variance in pca7.explained_variance_ratio_:\n",
    "#    component_number += 1\n",
    "#    print(f\"PC {component_number} : {variance.round(3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Understanding the meaning of each principal component by analyzing its factor loading</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing pca components\n",
    "#factor_loadings_df = pd.DataFrame(pd.np.transpose(pca7.components_))\n",
    "\n",
    "\n",
    "#Naming rows as original features\n",
    "#factor_loadings_df = factor_loadings_df.set_index(survey_answers_scaled_df.columns)\n",
    "\n",
    "\n",
    "#Checking the result\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 1\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,0][factor_loadings_df.iloc[:,0]>0.1].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,0][factor_loadings_df.iloc[:,0]<-0.18].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 2\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,1][factor_loadings_df.iloc[:,1]>0.25].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,1][factor_loadings_df.iloc[:,1]<-0.07].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 3\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,2][factor_loadings_df.iloc[:,2]>0.15].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,2][factor_loadings_df.iloc[:,2]<-0.16].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 4\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,3][factor_loadings_df.iloc[:,3]>0.19].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,3][factor_loadings_df.iloc[:,3]<-0.16].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 5\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,4][factor_loadings_df.iloc[:,4]>0.19].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,4][factor_loadings_df.iloc[:,4]<-0.11].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 6\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,5][factor_loadings_df.iloc[:,5]>0.18].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,5][factor_loadings_df.iloc[:,5]<-0.14].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n",
    "\n",
    "#print(f\"\"\"\n",
    "#---------------------------------------\n",
    "#FACTOR LOADING: PRINCIPAL COMPONENT 7\n",
    "#---------------------------------------\"\"\")\n",
    "#print(factor_loadings_df.iloc[:,6][factor_loadings_df.iloc[:,6]>0.18].sort_values(ascending = False))\n",
    "#print(\"\\n\")\n",
    "#print(factor_loadings_df.iloc[:,6][factor_loadings_df.iloc[:,6]<-0.14].sort_values(ascending = True))\n",
    "#print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the Principal Components based on the factor loadings \n",
    "#factor_loadings_df.columns = ['uninterested_folks',\n",
    "#                              'moody_folks',\n",
    "#                              'Introverts',\n",
    "#                              'people-centric/sympathetic_folks',\n",
    "#                              'relaxed/self-centric_folks',\n",
    "#                              'unimaginative_folks',\n",
    "#                              'commanding_speakers']\n",
    "\n",
    "#factor_loadings_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Analyzing how each surveyor fits into each of the Principal Components</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the earlier fit and transformed pca7 object into a Dataframe\n",
    "#pca7_survey_df = pd.DataFrame(pca7_survey)\n",
    "\n",
    "#Renaming columns\n",
    "#pca7_survey_df.columns = factor_loadings_df.columns\n",
    "\n",
    "#Displaying the results\n",
    "#pca7_survey_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><h4>PCA performed on the survey_answers_big5_scaled explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a PCA object without specific mention of components\n",
    "pca = PCA(n_components = None,\n",
    "          random_state = 222)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "pca_survey_big5 = pca.fit_transform(survey_answers_big5_scaled)\n",
    "\n",
    "#Comparing shapes\n",
    "print(\"Original shape:\", survey_answers_big5_scaled.shape)\n",
    "print(\"PCA shape     :\", pca_survey_big5.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Plotting a Scree plot to visually detect the number of principal components to be used.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the scree plot function\n",
    "scree_plot(pca_object=pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the Scree plot, it is a good choice to go with 7 Principal Components, as seen by the elbow of the plot at 7 PCA feature, after which there is very less change in explained variance.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanting a PCA object with just the first 7 PC's\n",
    "pca7 = PCA(n_components = 7,\n",
    "           random_state = 222)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "pca7_survey_big5 = pca7.fit_transform(survey_answers_big5_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Checking each components explained Variance ratio</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Component number counter\n",
    "component_number = 0\n",
    "\n",
    "\n",
    "#Looping over each principal component\n",
    "for variance in pca7.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    print(f\"PC {component_number} : {variance.round(3)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Understanding the meaning of each principal component by analyzing its factor loading</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing pca components\n",
    "factor_loadings_big5_df = pd.DataFrame(pd.np.transpose(pca7.components_))\n",
    "\n",
    "\n",
    "#Naming rows as original features\n",
    "factor_loadings_big5_df = factor_loadings_big5_df.set_index(survey_answers_big5_scaled_df.columns)\n",
    "\n",
    "\n",
    "#Checking the result\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 1\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,0][factor_loadings_big5_df.iloc[:,0]>0.16].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,0][factor_loadings_big5_df.iloc[:,0]<-0.17].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 2\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,1][factor_loadings_big5_df.iloc[:,1]>0.25].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,1][factor_loadings_big5_df.iloc[:,1]<-0.07].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 3\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,2][factor_loadings_big5_df.iloc[:,2]>0.15].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,2][factor_loadings_big5_df.iloc[:,2]<-0.16].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 4\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,3][factor_loadings_big5_df.iloc[:,3]>0.19].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,3][factor_loadings_big5_df.iloc[:,3]<-0.16].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 5\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,4][factor_loadings_big5_df.iloc[:,4]>0.19].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,4][factor_loadings_big5_df.iloc[:,4]<-0.11].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 6\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,5][factor_loadings_big5_df.iloc[:,5]>0.18].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,5][factor_loadings_big5_df.iloc[:,5]<-0.1].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 7\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_big5_df.iloc[:,6][factor_loadings_big5_df.iloc[:,6]>0.18].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_big5_df.iloc[:,6][factor_loadings_big5_df.iloc[:,6]<-0.14].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Naming the columns based on the factor loadings\n",
    "factor_loadings_big5_df.columns = ['prefer_isolation',\n",
    "                                   'moody',\n",
    "                                   'non_party_person',\n",
    "                                   'strong_verbal_aptitude',\n",
    "                                   'relaxed',\n",
    "                                   'systematic',\n",
    "                                   'creative']\n",
    "\n",
    "factor_loadings_big5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Analyzing how each surveyor fits into each of the Principal Components</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Converting the earlier fit and transformed pca7 object into a Dataframe\n",
    "pca7_survey_big5_df = pd.DataFrame(pca7_survey_big5)\n",
    "\n",
    "#Renaming columns\n",
    "pca7_survey_big5_df.columns = factor_loadings_big5_df.columns\n",
    "\n",
    "#Displaying the results\n",
    "pca7_survey_big5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><h4>PCA performed on the survey_answers_hultdna_scaled explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a PCA object without specific mention of components\n",
    "pca = PCA(n_components = None,\n",
    "          random_state = 206)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "pca_survey_hultdna = pca.fit_transform(survey_answers_hultdna_scaled)\n",
    "\n",
    "#Comparing shapes\n",
    "print(\"Original shape:\", survey_answers_hultdna_scaled.shape)\n",
    "print(\"PCA shape     :\", pca_survey_hultdna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Plotting a Scree plot to visually detect the number of principal components to be used.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the scree plot function\n",
    "scree_plot(pca_object=pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the Scree plot, it is a good choice to go with 4 Principal Components, as seen by the elbow of the plot at 4 PCA feature, after which there is very less change in explained variance.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanting a PCA object with just the first 4 PC's\n",
    "pca4 = PCA(n_components = 4,\n",
    "           random_state = 222)\n",
    "\n",
    "#Fitting and Transforming the scaled survey data\n",
    "pca4_survey_hultdna = pca4.fit_transform(survey_answers_hultdna_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Checking each components explained Variance ratio</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Component number counter\n",
    "component_number = 0\n",
    "\n",
    "\n",
    "#Looping over each principal component\n",
    "for variance in pca4.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    print(f\"PC {component_number} : {variance.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Understanding the meaning of each principal component by analyzing its factor loading</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposing pca components\n",
    "factor_loadings_hultdna_df = pd.DataFrame(pd.np.transpose(pca4.components_))\n",
    "\n",
    "\n",
    "#Naming rows as original features\n",
    "factor_loadings_hultdna_df = factor_loadings_hultdna_df.set_index(survey_answers_hultdna_scaled_df.columns)\n",
    "\n",
    "\n",
    "#Checking the result\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 1\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,0][factor_loadings_hultdna_df.iloc[:,0] > 0.05].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,0][factor_loadings_hultdna_df.iloc[:,0] < -0.23].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 2\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,1][factor_loadings_hultdna_df.iloc[:,1]>0.25].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,1][factor_loadings_hultdna_df.iloc[:,1]<-0.07].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 3\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,2][factor_loadings_hultdna_df.iloc[:,2]>0.15].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,2][factor_loadings_hultdna_df.iloc[:,2]<-0.1].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(f\"\"\"\n",
    "---------------------------------------\n",
    "FACTOR LOADING: PRINCIPAL COMPONENT 4\n",
    "---------------------------------------\"\"\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,3][factor_loadings_hultdna_df.iloc[:,3]>0.19].sort_values(ascending = False))\n",
    "print(\"\\n\")\n",
    "print(factor_loadings_hultdna_df.iloc[:,3][factor_loadings_hultdna_df.iloc[:,3]<-0.16].sort_values(ascending = True))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_loadings_hultdna_df.columns = ['not_so_bright',\n",
    "                                      'growth_mindset',\n",
    "                                      'unconvincing',\n",
    "                                      'inefficient']\n",
    "\n",
    "factor_loadings_hultdna_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><strong>Analyzing how each surveyor fits into each of the Principal Components</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the earlier fit and transformed pca7 object into a Dataframe\n",
    "pca4_survey_hultdna_df = pd.DataFrame(pca4_survey_hultdna)\n",
    "\n",
    "#Renaming columns\n",
    "pca4_survey_hultdna_df.columns = factor_loadings_hultdna_df.columns\n",
    "\n",
    "#Displaying the results\n",
    "pca4_survey_hultdna_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "***\n",
    "***\n",
    "***\n",
    "<h3>Clustering</h3>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Clustering using the chosen 7 Principal components of the survey answers explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the variance of the pca7_survey object\n",
    "#pd.np.var(pca7_survey_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Rescaling our data, as the variance among features is no longer same in the new dataset.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a Standard Scaler object\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the dataset\n",
    "#scaler.fit(pca7_survey_df)\n",
    "\n",
    "#Transforming the fit data\n",
    "#pca7_survey_scaled = scaler.transform(pca7_survey_df)\n",
    "\n",
    "#Converting it into a dataframe\n",
    "#pca7_survey_scaled_df = pd.DataFrame(pca7_survey_scaled)\n",
    "\n",
    "#Renaming the columns\n",
    "#pca7_survey_scaled_df.columns = factor_loadings_df.columns\n",
    "\n",
    "#Checking the variance\n",
    "#pd.np.var(pca7_survey_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Creating a dendogram to determine the number of cluster for KNN modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping data based on Ward distance\n",
    "#standard_mergings_ward = linkage(y = pca7_survey_scaled_df,\n",
    "#                                 method = 'ward')\n",
    "\n",
    "\n",
    "#Setting plot size\n",
    "#fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "#Developing a dendrogram\n",
    "#dendrogram(Z = standard_mergings_ward,\n",
    "#           leaf_rotation = 90,\n",
    "#           leaf_font_size = 6)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Plotting an inertia plot to see viable candidates for determining the number of clusters to be used in KMeans modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the inertia_plot function\n",
    "#inertia_plot(data = pca7_survey_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the inertia plot, lets use 5 clusters for building the KMeans model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING a k-Means object with five clusters\n",
    "#survey_answers_kmeans_pca = KMeans(n_clusters = 5,\n",
    "#                              random_state = 222)\n",
    "\n",
    "\n",
    "#Fitting the object to the data\n",
    "#survey_answers_kmeans_pca.fit(pca7_survey_scaled_df)\n",
    "\n",
    "\n",
    "#Converting the clusters to a DataFrame\n",
    "#survey_answers_kmeans_pca_df = pd.DataFrame({'Cluster': survey_answers_kmeans_pca.labels_})\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "#print(survey_answers_kmeans_pca_df.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Finding the centroids of each cluster, in an attempt to explain the underlying story of ideal members of each cluster.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object to store the cluster centers\n",
    "#centroids_survey_answers_kmeans_pca = survey_answers_kmeans_pca.cluster_centers_\n",
    "\n",
    "#Converting cluster centers into a dataframe\n",
    "#centroids_survey_answers_kmeans_pca_df = pd.DataFrame(centroids_survey_answers_kmeans_pca)\n",
    "\n",
    "#Renaming the columns\n",
    "#centroids_survey_answers_kmeans_pca_df.columns = pca7_survey_scaled_df.columns\n",
    "\n",
    "#Checking the results\n",
    "#centroids_survey_answers_kmeans_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the cluster and PCA components\n",
    "#cluster_pca_df = pd.concat([survey_answers_kmeans_pca_df,\n",
    "#                           pca7_survey_df],\n",
    "#                           axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "#cluster_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the earlier eliminated columns\n",
    "#final_cluster_pca_df = pd.concat([original_df.loc[:, ['target','current_laptop', 'surveyID', 'program', 'age', 'gender', 'nationality', 'ethnicity']],\n",
    "#                                 cluster_pca_df], \n",
    "#                                 axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "#final_cluster_pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Clustering using the chosen 7 Principal components of the survey answers big5 personality traits explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the variance of the pca7_survey object\n",
    "pd.np.var(pca7_survey_big5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Rescaling our data, as the variance among features is no longer same in the new dataset.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a Standard Scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the dataset\n",
    "scaler.fit(pca7_survey_big5_df)\n",
    "\n",
    "#Transforming the fit data\n",
    "pca7_survey_big5_scaled = scaler.transform(pca7_survey_big5_df)\n",
    "\n",
    "#Converting it into a dataframe\n",
    "pca7_survey_big5_scaled_df = pd.DataFrame(pca7_survey_big5_scaled)\n",
    "\n",
    "#Renaming the columns\n",
    "pca7_survey_big5_scaled_df.columns = factor_loadings_big5_df.columns\n",
    "\n",
    "#Checking the variance\n",
    "pd.np.var(pca7_survey_big5_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Creating a dendogram to determine the number of cluster for KNN modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y      = pca7_survey_big5_scaled_df,\n",
    "                                 method = 'ward')\n",
    "\n",
    "\n",
    "#Setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "#Developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation  = 90,\n",
    "           leaf_font_size = 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Plotting an inertia plot to see viable candidates for determining the number of clusters to be used in KMeans modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Calling the inertia_plot function\n",
    "inertia_plot(data = pca7_survey_big5_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the inertia plot, lets use 3 clusters for building the KMeans model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING a k-Means object with 3 clusters\n",
    "survey_answers_big5_kmeans_pca = KMeans(n_clusters   = 3,\n",
    "                                        random_state = 222)\n",
    "\n",
    "\n",
    "#Fitting the object to the data\n",
    "survey_answers_big5_kmeans_pca.fit(pca7_survey_big5_scaled_df)\n",
    "\n",
    "\n",
    "#Converting the clusters to a DataFrame\n",
    "survey_answers_big5_kmeans_pca_df = pd.DataFrame({'Cluster': survey_answers_big5_kmeans_pca.labels_})\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "print(survey_answers_big5_kmeans_pca_df.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Finding the centroids of each cluster, in an attempt to explain the underlying story of ideal members of each cluster.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object to store the cluster centers\n",
    "centroids_survey_answers_big5_kmeans_pca = survey_answers_big5_kmeans_pca.cluster_centers_\n",
    "\n",
    "#Converting cluster centers into a dataframe\n",
    "centroids_survey_answers_big5_kmeans_pca_df = pd.DataFrame(centroids_survey_answers_big5_kmeans_pca)\n",
    "\n",
    "#Renaming the columns\n",
    "centroids_survey_answers_big5_kmeans_pca_df.columns = pca7_survey_big5_scaled_df.columns\n",
    "\n",
    "#Checking the results\n",
    "centroids_survey_answers_big5_kmeans_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the cluster and PCA components\n",
    "cluster_pca_big5_df = pd.concat([survey_answers_big5_kmeans_pca_df,\n",
    "                                pca7_survey_big5_df],\n",
    "                                axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "cluster_pca_big5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the earlier eliminated columns\n",
    "final_cluster_pca_big5_df = pd.concat([original_df.loc[:, ['preferred_laptop','current_laptop', 'surveyID', 'program', 'age', 'gender', 'nationality', 'ethnicity']],\n",
    "                                      cluster_pca_big5_df], \n",
    "                                      axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "final_cluster_pca_big5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Gaining greater insights\n",
    "strong_verbal_aptitude = final_cluster_pca_big5_df[['strong_verbal_aptitude', 'Cluster', 'current_laptop', 'preferred_laptop']][final_cluster_pca_big5_df['strong_verbal_aptitude']>1.0]\n",
    "\n",
    "print(strong_verbal_aptitude)\n",
    "print(\"\\n\\n\")\n",
    "print(strong_verbal_aptitude['current_laptop'].value_counts())\n",
    "print(\"\\n\\n\")\n",
    "print(strong_verbal_aptitude['preferred_laptop'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>INSIGHT:</strong><br>People belonging to the Principal component which says they have a strong verbal aptitude are most likely to own a Macbook as well as say they would prefer a Macbook over a PC.<br>This is also backed up with research conducted by  <a href=\"https://www.hongkiat.com/blog/mac-vs-pc-myth-busting-consumer-guide/\">Nina Krimly</a> and research by <a href=\"https://www.huffpost.com/entry/mac-vs-pc-what-your-os-says-about-you_n_852170\">Thomas Houston</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Gaining greater insights\n",
    "non_party_person = final_cluster_pca_big5_df[['non_party_person', 'Cluster', 'current_laptop', 'preferred_laptop']][final_cluster_pca_big5_df['non_party_person']>1.0]\n",
    "\n",
    "print(non_party_person)\n",
    "print(\"\\n\\n\")\n",
    "print(non_party_person['current_laptop'].value_counts())\n",
    "print(\"\\n\\n\")\n",
    "print(non_party_person['preferred_laptop'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT 3:</strong><br>People who don't like partying or even throwing a party, are likely to currently own a Windows laptop and probably would prefer a Windows Laptop. However the count of people not interested in parties and who prefer a Windows or a Mac is almost the same, if price for both is equal.<br>This is backed up by external research from <a href=\"https://www.hongkiat.com/blog/mac-vs-pc-myth-busting-consumer-guide/\">Nina Krimly</a> and research by <a href=\"https://www.huffpost.com/entry/mac-vs-pc-what-your-os-says-about-you_n_852170\">Thomas Houston</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Clustering using the chosen 4 Principal components of the survey answers hult dna explanatory variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the variance of the pca7_survey object\n",
    "pd.np.var(pca4_survey_hultdna_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Rescaling our data, as the variance among features is no longer same in the new dataset.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating a Standard Scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fitting the scaler object to the dataset\n",
    "scaler.fit(pca4_survey_hultdna_df)\n",
    "\n",
    "#Transforming the fit data\n",
    "pca4_survey_hultdna_scaled = scaler.transform(pca4_survey_hultdna_df)\n",
    "\n",
    "#Converting it into a dataframe\n",
    "pca4_survey_hultdna_scaled_df = pd.DataFrame(pca4_survey_hultdna_scaled)\n",
    "\n",
    "#Renaming the columns\n",
    "pca4_survey_hultdna_scaled_df.columns = factor_loadings_hultdna_df.columns\n",
    "\n",
    "#Checking the variance\n",
    "pd.np.var(pca4_survey_hultdna_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><strong>Creating a dendogram to determine the number of cluster for KNN modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = pca4_survey_hultdna_scaled_df,\n",
    "                                 method = 'ward')\n",
    "\n",
    "\n",
    "#Setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "#Developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation  = 90,\n",
    "           leaf_font_size = 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Plotting an inertia plot to see viable candidates for determining the number of clusters to be used in KMeans modeling</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the inertia_plot function\n",
    "inertia_plot(data = pca4_survey_hultdna_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Based on the inertia plot, lets use 4 clusters for building the KMeans model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATING a k-Means object with five clusters\n",
    "survey_answers_hultdna_kmeans_pca = KMeans(n_clusters   = 4,\n",
    "                                           random_state = 222)\n",
    "\n",
    "\n",
    "#Fitting the object to the data\n",
    "survey_answers_hultdna_kmeans_pca.fit(pca4_survey_hultdna_scaled_df)\n",
    "\n",
    "\n",
    "#Converting the clusters to a DataFrame\n",
    "survey_answers_hultdna_kmeans_pca_df = pd.DataFrame({'Cluster': survey_answers_hultdna_kmeans_pca.labels_})\n",
    "\n",
    "\n",
    "#Checking the results\n",
    "print(survey_answers_hultdna_kmeans_pca_df.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Finding the centroids of each cluster, in an attempt to explain the underlying story of ideal members of each cluster.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an object to store the cluster centers\n",
    "centroids_survey_answers_hultdna_kmeans_pca = survey_answers_hultdna_kmeans_pca.cluster_centers_\n",
    "\n",
    "#Converting cluster centers into a dataframe\n",
    "centroids_survey_answers_hultdna_kmeans_pca_df = pd.DataFrame(centroids_survey_answers_hultdna_kmeans_pca)\n",
    "\n",
    "#Renaming the columns\n",
    "centroids_survey_answers_hultdna_kmeans_pca_df.columns = pca4_survey_hultdna_scaled_df.columns\n",
    "\n",
    "#Checking the results\n",
    "centroids_survey_answers_hultdna_kmeans_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the cluster and PCA components\n",
    "cluster_pca_hultdna_df = pd.concat([survey_answers_hultdna_kmeans_pca_df,\n",
    "                                   pca4_survey_hultdna_df],\n",
    "                                   axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "cluster_pca_hultdna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the earlier eliminated columns\n",
    "final_cluster_pca_hultdna_df = pd.concat([original_df.loc[:, ['preferred_laptop','current_laptop', 'surveyID', 'program', 'age', 'gender', 'nationality', 'ethnicity']],\n",
    "                                         cluster_pca_hultdna_df], \n",
    "                                         axis = 1)\n",
    "\n",
    "#Checking the results\n",
    "final_cluster_pca_hultdna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#Gaining greater insights\n",
    "growth_mindset = final_cluster_pca_hultdna_df[['growth_mindset', 'Cluster', 'current_laptop', 'preferred_laptop']][final_cluster_pca_hultdna_df['growth_mindset']>1.0]\n",
    "\n",
    "print(growth_mindset)\n",
    "print(\"\\n\\n\")\n",
    "print(growth_mindset['Cluster'].value_counts())\n",
    "print(\"\\n\\n\")\n",
    "print(growth_mindset['current_laptop'].value_counts())\n",
    "print(\"\\n\\n\")\n",
    "print(growth_mindset['preferred_laptop'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT 2:</strong><br> People belonging to the Growth Mindset persona (Principal Component) and mostly in Cluster 1, currently own a Windows Laptop, as seen from the standard deviation value greater than 1. But given a choice of prices being equal for both Macbook and Windows, people in the Growth Mindset persona would marginally prefer Macbook over a Windows laptop. As such Microsoft should target students, who carry a growth mindset, as most likely they would prefer currently owning a Windows laptop and also preferably stick with it in the future.<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "***\n",
    "***\n",
    "***\n",
    "<h3>Boxplots</h3>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating boxplots of the Principal components for the survey answers regarding Hult DNA, with regards to the current laptop that they posses</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_so_bright_kid\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'not_so_bright',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teamplayer\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'growth_mindset',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unconvincing\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'unconvincing',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#talented_but_not_a_teamplayer\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'inefficient',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating boxplots of the Principal components for the survey answers regarding Hult DNA, separated by future laptop choice</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#talented_but_not_a_teamplayer\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'not_so_bright',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teamplayer\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'growth_mindset',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT:</strong><br>For the \"teamplayer\" principal component, there is a big difference in mean between the surveyors who want to buy Chromebook, compared to the ones who wanna buy Macbook/Windows laptop, when asked this question. Implying, people belonging to this cluster as well as this particular principal component, have a desire to buy chromebook more than any other laptop.<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unconvincing\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'unconvincing',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT:</strong><br>For the \"unconvincing\" principal component, for clusters 1 and 2, there tend to be fewer Chromebook buyers than Macbook/Windows, as seen by the lower mean line.<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#talented_but_not_a_teamplayer\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'inefficient',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_hultdna_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT:</strong><br>For \"talented_but_not_a_teamplayer\" principal component, people belonging to cluster 1 tend to show a greater desire to buy Chromebook, than Macbook/Windows, as seen by the higher mean.<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating boxplots of the Principal components for the big5 personality traits survey answers, separated by current laptop.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uninterested\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'prefer_isolation',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moody\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'moody',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introverts\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'non_party_person',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predominant\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'strong_verbal_aptitude',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creative_but_messy\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'relaxed',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#systematic\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'systematic',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#respectful\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'current_laptop',\n",
    "#            y    = 'creative',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating boxplots of the Principal components for the big5 personality traits survey answers, separated by future laptop choice</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uninterested\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'prefer_isolation',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moody\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'moody',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT:</strong><br>People belonging to the \"moody\" principal component and cluster 0, show a big variance, however prefer to buy Chromebook.<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introverts\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'non_party_person',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>INSIGHT:</strong><br>People belonging to the \"introverts\" component and to clusters 0, 1, do not prefer to buy the Chromebook and would like to buy the Windows or the Macbook.<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predominant\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'strong_verbal_aptitude',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creative_but_messy\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'relaxed',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#systematic\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'systematic',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#respectful\n",
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x    = 'preferred_laptop',\n",
    "#            y    = 'creative',\n",
    "#            hue  = 'Cluster',\n",
    "#            data = final_cluster_pca_big5_df)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
